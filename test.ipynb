{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Air Quality Data:\n",
      "{'aqi': 294, 'idx': 2554, 'attributions': [{'url': 'http://cpcb.nic.in/', 'name': 'CPCB - India Central Pollution Control Board', 'logo': 'India-CPCB.png'}, {'url': 'http://dpccairdata.com/', 'name': 'Delhi Pollution Control Commitee (Government of NCT of Delhi)', 'logo': 'India-DPCCC.png'}, {'url': 'https://waqi.info/', 'name': 'World Air Quality Index Project'}], 'city': {'geo': [28.6341, 77.2005], 'name': 'Mandir Marg, Delhi, Delhi, India', 'url': 'https://aqicn.org/city/delhi/mandir-marg', 'location': ''}, 'dominentpol': 'pm25', 'iaqi': {'co': {'v': 8.2}, 'dew': {'v': 14}, 'h': {'v': 86.65}, 'no2': {'v': 36}, 'o3': {'v': 15.6}, 'p': {'v': 985.95}, 'pm10': {'v': 189}, 'pm25': {'v': 294}, 'so2': {'v': 3.7}, 't': {'v': 29.025000000000002}, 'w': {'v': 0.22499999999999998}, 'wd': {'v': 75.3}}, 'time': {'s': '2024-11-04 11:00:00', 'tz': '+05:30', 'v': 1730718000, 'iso': '2024-11-04T11:00:00+05:30'}, 'forecast': {'daily': {'o3': [{'avg': 7, 'day': '2024-11-02', 'max': 37, 'min': 1}, {'avg': 6, 'day': '2024-11-03', 'max': 35, 'min': 1}, {'avg': 9, 'day': '2024-11-04', 'max': 57, 'min': 1}, {'avg': 7, 'day': '2024-11-05', 'max': 45, 'min': 1}, {'avg': 5, 'day': '2024-11-06', 'max': 49, 'min': 1}, {'avg': 5, 'day': '2024-11-07', 'max': 40, 'min': 1}, {'avg': 4, 'day': '2024-11-08', 'max': 37, 'min': 1}, {'avg': 1, 'day': '2024-11-09', 'max': 1, 'min': 1}], 'pm10': [{'avg': 72, 'day': '2024-11-02', 'max': 73, 'min': 70}, {'avg': 78, 'day': '2024-11-03', 'max': 85, 'min': 58}, {'avg': 96, 'day': '2024-11-04', 'max': 123, 'min': 70}, {'avg': 82, 'day': '2024-11-05', 'max': 113, 'min': 62}, {'avg': 82, 'day': '2024-11-06', 'max': 113, 'min': 62}, {'avg': 87, 'day': '2024-11-07', 'max': 123, 'min': 65}, {'avg': 76, 'day': '2024-11-08', 'max': 85, 'min': 65}, {'avg': 75, 'day': '2024-11-09', 'max': 85, 'min': 62}, {'avg': 73, 'day': '2024-11-10', 'max': 73, 'min': 58}], 'pm25': [{'avg': 165, 'day': '2024-11-02', 'max': 171, 'min': 159}, {'avg': 170, 'day': '2024-11-03', 'max': 174, 'min': 159}, {'avg': 207, 'day': '2024-11-04', 'max': 252, 'min': 162}, {'avg': 175, 'day': '2024-11-05', 'max': 186, 'min': 159}, {'avg': 176, 'day': '2024-11-06', 'max': 186, 'min': 159}, {'avg': 177, 'day': '2024-11-07', 'max': 186, 'min': 159}, {'avg': 172, 'day': '2024-11-08', 'max': 174, 'min': 160}, {'avg': 171, 'day': '2024-11-09', 'max': 174, 'min': 159}, {'avg': 173, 'day': '2024-11-10', 'max': 174, 'min': 159}], 'uvi': [{'avg': 0, 'day': '2024-11-03', 'max': 0, 'min': 0}, {'avg': 1, 'day': '2024-11-04', 'max': 4, 'min': 0}, {'avg': 1, 'day': '2024-11-05', 'max': 4, 'min': 0}, {'avg': 1, 'day': '2024-11-06', 'max': 4, 'min': 0}, {'avg': 1, 'day': '2024-11-07', 'max': 4, 'min': 0}, {'avg': 2, 'day': '2024-11-08', 'max': 4, 'min': 0}]}}, 'debug': {'sync': '2024-11-04T14:35:09+09:00'}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.waqi.info/feed/here/\"\n",
    "token = \"f72812a3dce2b2328992b2b06e42f4bc8e9f30da\"\n",
    "\n",
    "request_url = f\"{url}?token={token}\"\n",
    "# Fetch the data from the API\n",
    "response = requests.get(request_url)\n",
    "\n",
    "# Check if the response is successful\n",
    "if response.status_code == 200:\n",
    "    data = response.json()  # Parse JSON response\n",
    "    if data.get(\"status\") == \"ok\":\n",
    "        print(\"Air Quality Data:\")\n",
    "        print(data[\"data\"])\n",
    "    else:\n",
    "        print(\"Error fetching data:\", data.get(\"data\"))\n",
    "else:\n",
    "    print(f\"Failed to connect. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# API endpoint and token\n",
    "url = \"https://api.waqi.info/feed/here/\"\n",
    "token = \"f72812a3dce2b2328992b2b06e42f4bc8e9f30da\"\n",
    "\n",
    "# Create the request URL\n",
    "request_url = f\"{url}?token={token}\"\n",
    "\n",
    "# Fetch the data from the API\n",
    "response = requests.get(request_url)\n",
    "\n",
    "# Check if the response is successful\n",
    "if response.status_code == 200:\n",
    "    data = response.json()  # Parse JSON response\n",
    "    if data.get(\"status\") == \"ok\":\n",
    "        air_quality_data = data[\"data\"]\n",
    "\n",
    "        # Extract input features (weather and pollutants)\n",
    "        iaqi_data = air_quality_data.get(\"iaqi\", {})\n",
    "        features = {\n",
    "            \"temperature\": iaqi_data.get(\"t\", {}).get(\"v\", None),\n",
    "            \"humidity\": iaqi_data.get(\"h\", {}).get(\"v\", None),\n",
    "            \"pressure\": iaqi_data.get(\"p\", {}).get(\"v\", None),\n",
    "            \"wind_speed\": iaqi_data.get(\"w\", {}).get(\"v\", None),\n",
    "            \"wind_direction\": iaqi_data.get(\"wd\", {}).get(\"v\", None),\n",
    "            \"pm25\": iaqi_data.get(\"pm25\", {}).get(\"v\", None),\n",
    "            \"pm10\": iaqi_data.get(\"pm10\", {}).get(\"v\", None),\n",
    "            \"no2\": iaqi_data.get(\"no2\", {}).get(\"v\", None),\n",
    "            \"so2\": iaqi_data.get(\"so2\", {}).get(\"v\", None),\n",
    "            \"o3\": iaqi_data.get(\"o3\", {}).get(\"v\", None),\n",
    "            \"co\": iaqi_data.get(\"co\", {}).get(\"v\", None)\n",
    "        }\n",
    "\n",
    "        # Extract target (AQI)\n",
    "        target = air_quality_data.get(\"aqi\", None)\n",
    "\n",
    "\n",
    "        # Convert to a DataFrame for easy manipulation (optional)\n",
    "        data_frame = pd.DataFrame([features])\n",
    "        data_frame['target_aqi'] = target\n",
    "        data_frame.to_csv(\"check.csv\")\n",
    "\n",
    "    else:\n",
    "        print(\"Error fetching data:\", data.get(\"data\"))\n",
    "else:\n",
    "    print(f\"Failed to connect. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mkdir air_quality_feature_store\n",
    "# cd air_quality_feature_store\n",
    "# feast init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "FeatureView.__init__() got an unexpected keyword argument 'batch_source'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeast\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FeatureView, Field\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeast\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Float32\n\u001b[0;32m---> 20\u001b[0m air_quality_feature_view \u001b[38;5;241m=\u001b[39m \u001b[43mFeatureView\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mair_quality_features\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mentities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mttl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mField\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mField\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhumidity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mField\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpressure\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mField\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwind_speed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mField\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwind_direction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mField\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpm25\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mField\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpm10\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mField\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mno2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mField\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mso2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mField\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mo3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mField\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mco\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43monline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_source\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Specify your batch source here\u001b[39;49;00m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Register the feature view\u001b[39;00m\n\u001b[1;32m     43\u001b[0m store\u001b[38;5;241m.\u001b[39mapply([location, air_quality_feature_view])\n",
      "\u001b[0;31mTypeError\u001b[0m: FeatureView.__init__() got an unexpected keyword argument 'batch_source'"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from feast import FeatureStore, Entity, Feature, ValueType\n",
    "import pandas as pd\n",
    "\n",
    "# Set up the connection to the feature store\n",
    "store = FeatureStore(repo_path=\"/home/jellyfish/Music/Air Quality Index Predictor/air_quality_feature_store/set_cod/feature_repo/\")\n",
    "\n",
    "# Define an entity for the feature store (e.g., a location ID)\n",
    "location = Entity(\n",
    "    name=\"location\",\n",
    "    join_keys=[\"location_id\"],\n",
    "    value_type=ValueType.STRING,\n",
    "    description=\"Identifier for different locations\"\n",
    ")\n",
    "\n",
    "from feast import FeatureView, Field\n",
    "from feast.types import Float32\n",
    "\n",
    "air_quality_feature_view = FeatureView(\n",
    "    name=\"air_quality_features\",\n",
    "    entities=[\"location\"],\n",
    "    ttl=None,\n",
    "    schema=[\n",
    "        Field(name=\"temperature\", dtype=Float32),\n",
    "        Field(name=\"humidity\", dtype=Float32),\n",
    "        Field(name=\"pressure\", dtype=Float32),\n",
    "        Field(name=\"wind_speed\", dtype=Float32),\n",
    "        Field(name=\"wind_direction\", dtype=Float32),\n",
    "        Field(name=\"pm25\", dtype=Float32),\n",
    "        Field(name=\"pm10\", dtype=Float32),\n",
    "        Field(name=\"no2\", dtype=Float32),\n",
    "        Field(name=\"so2\", dtype=Float32),\n",
    "        Field(name=\"o3\", dtype=Float32),\n",
    "        Field(name=\"co\", dtype=Float32)\n",
    "    ],\n",
    "    online=True,\n",
    "    batch_source=None,  # Specify your batch source here\n",
    "    tags={}\n",
    ")\n",
    "\n",
    "# Register the feature view\n",
    "store.apply([location, air_quality_feature_view])\n",
    "\n",
    "# Create a DataFrame for ingestion\n",
    "data = pd.DataFrame([{\n",
    "    \"location_id\": \"delhi_mandir_marg\",\n",
    "    \"event_timestamp\": datetime.utcnow(),\n",
    "    \"temperature\": 29.025,\n",
    "    \"humidity\": 86.65,\n",
    "    \"pressure\": 985.95,\n",
    "    \"wind_speed\": 0.225,\n",
    "    \"wind_direction\": 75.3,\n",
    "    \"pm25\": 294,\n",
    "    \"pm10\": 189,\n",
    "    \"no2\": 36,\n",
    "    \"so2\": 3.7,\n",
    "    \"o3\": 15.6,\n",
    "    \"co\": 8.2\n",
    "}])\n",
    "\n",
    "# Ingest data into the feature store\n",
    "store.write_to_online_store(\"air_quality_features\", data)\n",
    "\n",
    "print(\"Data successfully ingested into the feature store.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data appended at: 2024-11-04 06:49:33.583468\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNew data appended at:\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent_timestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Wait for 1 hour (3600 seconds)\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3600\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Define the API endpoint and token\n",
    "API_URL = \"https://api.waqi.info/feed/here/?token=f72812a3dce2b2328992b2b06e42f4bc8e9f30da\"\n",
    "CSV_FILE_PATH = \"air_quality_feature_store.csv\"\n",
    "\n",
    "# Function to fetch data from the API\n",
    "def fetch_air_quality_data():\n",
    "    try:\n",
    "        response = requests.get(API_URL)\n",
    "        response.raise_for_status()  # Raise an error for bad responses (4xx or 5xx)\n",
    "        \n",
    "        data = response.json()\n",
    "        if 'data' in data and data['data'] is not None:\n",
    "            iaqi = data['data'].get('iaqi', {})\n",
    "            return {\n",
    "                \"location_id\": \"delhi_mandir_marg\",\n",
    "                \"event_timestamp\": datetime.utcnow(),\n",
    "                \"temperature\": iaqi.get('t', {}).get('v', None),\n",
    "                \"humidity\": iaqi.get('h', {}).get('v', None),\n",
    "                \"pressure\": iaqi.get('p', {}).get('v', None),\n",
    "                \"wind_speed\": iaqi.get('w', {}).get('v', None),\n",
    "                \"wind_direction\": iaqi.get('wd', {}).get('v', None),\n",
    "                \"pm25\": iaqi.get('pm25', {}).get('v', None),\n",
    "                \"pm10\": iaqi.get('pm10', {}).get('v', None),\n",
    "                \"no2\": iaqi.get('no2', {}).get('v', None),\n",
    "                \"so2\": iaqi.get('so2', {}).get('v', None),\n",
    "                \"o3\": iaqi.get('o3', {}).get('v', None),\n",
    "                \"co\": iaqi.get('co', {}).get('v', None)\n",
    "            }\n",
    "        else:\n",
    "            print(\"No data found in API response.\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"Error fetching data:\", e)\n",
    "        return None\n",
    "\n",
    "# Function to append data to CSV\n",
    "def append_data_to_csv(data_dict, file_path):\n",
    "    # Check if the file exists to write the header only if needed\n",
    "    file_exists = os.path.isfile(file_path)\n",
    "    df = pd.DataFrame([data_dict])\n",
    "    \n",
    "    try:\n",
    "        if not file_exists:\n",
    "            df.to_csv(file_path, index=False, mode='w')  # Create new file with header\n",
    "        else:\n",
    "            df.to_csv(file_path, index=False, mode='a', header=False)  # Append without header\n",
    "    except Exception as e:\n",
    "        print(\"Error writing to CSV:\", e)\n",
    "\n",
    "# Main loop to fetch data every hour and update CSV\n",
    "while True:\n",
    "    new_data = fetch_air_quality_data()\n",
    "    if new_data:\n",
    "        append_data_to_csv(new_data, CSV_FILE_PATH)\n",
    "        print(\"New data appended at:\", new_data[\"event_timestamp\"])\n",
    "    \n",
    "    # Wait for 1 hour (3600 seconds)\n",
    "    time.sleep(3600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data appended for date: 2005-02-17 06:55:04.631370\n",
      "New data appended for date: 2005-02-17 07:55:04.631370\n",
      "New data appended for date: 2005-02-17 08:55:04.631370\n",
      "New data appended for date: 2005-02-17 09:55:04.631370\n",
      "New data appended for date: 2005-02-17 10:55:04.631370\n",
      "New data appended for date: 2005-02-17 11:55:04.631370\n",
      "New data appended for date: 2005-02-17 12:55:04.631370\n",
      "New data appended for date: 2005-02-17 13:55:04.631370\n",
      "New data appended for date: 2005-02-17 14:55:04.631370\n",
      "New data appended for date: 2005-02-17 15:55:04.631370\n",
      "New data appended for date: 2005-02-17 16:55:04.631370\n",
      "New data appended for date: 2005-02-17 17:55:04.631370\n",
      "New data appended for date: 2005-02-17 18:55:04.631370\n",
      "New data appended for date: 2005-02-17 19:55:04.631370\n",
      "New data appended for date: 2005-02-17 20:55:04.631370\n",
      "New data appended for date: 2005-02-17 21:55:04.631370\n",
      "New data appended for date: 2005-02-17 22:55:04.631370\n",
      "New data appended for date: 2005-02-17 23:55:04.631370\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 65\u001b[0m\n\u001b[1;32m     63\u001b[0m current_date \u001b[38;5;241m=\u001b[39m start_date\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m current_date \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m end_date:\n\u001b[0;32m---> 65\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_air_quality_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new_data:\n\u001b[1;32m     67\u001b[0m         append_data_to_csv(new_data, CSV_FILE_PATH)\n",
      "Cell \u001b[0;32mIn[12], line 16\u001b[0m, in \u001b[0;36mfetch_air_quality_data\u001b[0;34m(timestamp)\u001b[0m\n\u001b[1;32m     14\u001b[0m request_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mAPI_URL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&timestamp=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(timestamp\u001b[38;5;241m.\u001b[39mtimestamp())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Adjust according to the actual API format\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()  \u001b[38;5;66;03m# Raise an error for bad responses (4xx or 5xx)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    809\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 467\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:1099\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[0;32m-> 1099\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mproxy_is_verified:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connection.py:616\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    615\u001b[0m     sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    617\u001b[0m     server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[1;32m    618\u001b[0m     tls_in_tls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connection.py:198\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m:return: New socket connection.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 198\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[1;32m     75\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# Define the API endpoint and token\n",
    "API_URL = \"https://api.waqi.info/feed/here/?token=f72812a3dce2b2328992b2b06e42f4bc8e9f30da\"\n",
    "CSV_FILE_PATH = \"air_quality_feature_store.csv\"\n",
    "\n",
    "# Function to fetch data from the API\n",
    "def fetch_air_quality_data(timestamp):\n",
    "    # Modify the API URL to include a timestamp (if applicable)\n",
    "    # Here, we assume the API can take a timestamp parameter in a suitable format\n",
    "    request_url = f\"{API_URL}&timestamp={int(timestamp.timestamp())}\"  # Adjust according to the actual API format\n",
    "    try:\n",
    "        response = requests.get(request_url)\n",
    "        response.raise_for_status()  # Raise an error for bad responses (4xx or 5xx)\n",
    "        \n",
    "        data = response.json()\n",
    "        if 'data' in data and data['data'] is not None:\n",
    "            iaqi = data['data'].get('iaqi', {})\n",
    "            return {\n",
    "                \"location_id\": \"delhi_mandir_marg\",\n",
    "                \"event_timestamp\": timestamp,  # Use the passed timestamp\n",
    "                \"temperature\": iaqi.get('t', {}).get('v', None),\n",
    "                \"humidity\": iaqi.get('h', {}).get('v', None),\n",
    "                \"pressure\": iaqi.get('p', {}).get('v', None),\n",
    "                \"wind_speed\": iaqi.get('w', {}).get('v', None),\n",
    "                \"wind_direction\": iaqi.get('wd', {}).get('v', None),\n",
    "                \"pm25\": iaqi.get('pm25', {}).get('v', None),\n",
    "                \"pm10\": iaqi.get('pm10', {}).get('v', None),\n",
    "                \"no2\": iaqi.get('no2', {}).get('v', None),\n",
    "                \"so2\": iaqi.get('so2', {}).get('v', None),\n",
    "                \"o3\": iaqi.get('o3', {}).get('v', None),\n",
    "                \"co\": iaqi.get('co', {}).get('v', None)\n",
    "            }\n",
    "        else:\n",
    "            print(\"No data found in API response.\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"Error fetching data:\", e)\n",
    "        return None\n",
    "\n",
    "# Function to append data to CSV\n",
    "def append_data_to_csv(data_dict, file_path):\n",
    "    # Check if the file exists to write the header only if needed\n",
    "    file_exists = os.path.isfile(file_path)\n",
    "    df = pd.DataFrame([data_dict])\n",
    "    \n",
    "    try:\n",
    "        if not file_exists:\n",
    "            df.to_csv(file_path, index=False, mode='w')  # Create new file with header\n",
    "        else:\n",
    "            df.to_csv(file_path, index=False, mode='a', header=False)  # Append without header\n",
    "    except Exception as e:\n",
    "        print(\"Error writing to CSV:\", e)\n",
    "\n",
    "# Define the date range for historical data (e.g., past 7 days)\n",
    "start_date = datetime.utcnow() - timedelta(days=7200)  # Adjust the range as needed\n",
    "end_date = datetime.utcnow()\n",
    "\n",
    "# Generate timestamps for each hour in the date range\n",
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "    new_data = fetch_air_quality_data(current_date)\n",
    "    if new_data:\n",
    "        append_data_to_csv(new_data, CSV_FILE_PATH)\n",
    "        print(\"New data appended for date:\", new_data[\"event_timestamp\"])\n",
    "    \n",
    "    # Move to the next hour\n",
    "    current_date += timedelta(hours=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data appended for date: 2005-02-17 06:57:54.304822\n",
      "New data appended for date: 2005-02-17 07:57:54.304822\n",
      "New data appended for date: 2005-02-17 08:57:54.304822\n",
      "New data appended for date: 2005-02-17 09:57:54.304822\n",
      "New data appended for date: 2005-02-17 10:57:54.304822\n",
      "New data appended for date: 2005-02-17 11:57:54.304822\n",
      "New data appended for date: 2005-02-17 12:57:54.304822\n",
      "New data appended for date: 2005-02-17 13:57:54.304822\n",
      "New data appended for date: 2005-02-17 14:57:54.304822\n",
      "New data appended for date: 2005-02-17 15:57:54.304822\n",
      "New data appended for date: 2005-02-17 16:57:54.304822\n",
      "New data appended for date: 2005-02-17 17:57:54.304822\n",
      "New data appended for date: 2005-02-17 18:57:54.304822\n",
      "New data appended for date: 2005-02-17 19:57:54.304822\n",
      "New data appended for date: 2005-02-17 20:57:54.304822\n",
      "New data appended for date: 2005-02-17 21:57:54.304822\n",
      "New data appended for date: 2005-02-17 22:57:54.304822\n",
      "New data appended for date: 2005-02-17 23:57:54.304822\n",
      "New data appended for date: 2005-02-18 00:57:54.304822\n",
      "New data appended for date: 2005-02-18 01:57:54.304822\n",
      "New data appended for date: 2005-02-18 02:57:54.304822\n",
      "New data appended for date: 2005-02-18 03:57:54.304822\n",
      "New data appended for date: 2005-02-18 04:57:54.304822\n",
      "New data appended for date: 2005-02-18 05:57:54.304822\n",
      "New data appended for date: 2005-02-18 06:57:54.304822\n",
      "New data appended for date: 2005-02-18 07:57:54.304822\n",
      "New data appended for date: 2005-02-18 08:57:54.304822\n",
      "New data appended for date: 2005-02-18 09:57:54.304822\n",
      "New data appended for date: 2005-02-18 10:57:54.304822\n",
      "New data appended for date: 2005-02-18 11:57:54.304822\n",
      "New data appended for date: 2005-02-18 12:57:54.304822\n",
      "New data appended for date: 2005-02-18 13:57:54.304822\n",
      "New data appended for date: 2005-02-18 14:57:54.304822\n",
      "New data appended for date: 2005-02-18 15:57:54.304822\n",
      "New data appended for date: 2005-02-18 16:57:54.304822\n",
      "New data appended for date: 2005-02-18 17:57:54.304822\n",
      "New data appended for date: 2005-02-18 18:57:54.304822\n",
      "New data appended for date: 2005-02-18 19:57:54.304822\n",
      "New data appended for date: 2005-02-18 20:57:54.304822\n",
      "New data appended for date: 2005-02-18 21:57:54.304822\n",
      "New data appended for date: 2005-02-18 22:57:54.304822\n",
      "New data appended for date: 2005-02-18 23:57:54.304822\n",
      "New data appended for date: 2005-02-19 00:57:54.304822\n",
      "New data appended for date: 2005-02-19 01:57:54.304822\n",
      "New data appended for date: 2005-02-19 02:57:54.304822\n",
      "New data appended for date: 2005-02-19 03:57:54.304822\n",
      "New data appended for date: 2005-02-19 04:57:54.304822\n",
      "New data appended for date: 2005-02-19 05:57:54.304822\n",
      "New data appended for date: 2005-02-19 06:57:54.304822\n",
      "New data appended for date: 2005-02-19 07:57:54.304822\n",
      "New data appended for date: 2005-02-19 08:57:54.304822\n",
      "New data appended for date: 2005-02-19 09:57:54.304822\n",
      "New data appended for date: 2005-02-19 10:57:54.304822\n",
      "New data appended for date: 2005-02-19 11:57:54.304822\n",
      "New data appended for date: 2005-02-19 12:57:54.304822\n",
      "New data appended for date: 2005-02-19 13:57:54.304822\n",
      "New data appended for date: 2005-02-19 14:57:54.304822\n",
      "New data appended for date: 2005-02-19 15:57:54.304822\n",
      "New data appended for date: 2005-02-19 16:57:54.304822\n",
      "New data appended for date: 2005-02-19 17:57:54.304822\n",
      "New data appended for date: 2005-02-19 18:57:54.304822\n",
      "New data appended for date: 2005-02-19 19:57:54.304822\n",
      "New data appended for date: 2005-02-19 20:57:54.304822\n",
      "New data appended for date: 2005-02-19 21:57:54.304822\n",
      "New data appended for date: 2005-02-19 22:57:54.304822\n",
      "New data appended for date: 2005-02-19 23:57:54.304822\n",
      "New data appended for date: 2005-02-20 00:57:54.304822\n",
      "New data appended for date: 2005-02-20 01:57:54.304822\n",
      "New data appended for date: 2005-02-20 02:57:54.304822\n",
      "New data appended for date: 2005-02-20 03:57:54.304822\n",
      "New data appended for date: 2005-02-20 04:57:54.304822\n",
      "New data appended for date: 2005-02-20 05:57:54.304822\n",
      "New data appended for date: 2005-02-20 06:57:54.304822\n",
      "New data appended for date: 2005-02-20 07:57:54.304822\n",
      "New data appended for date: 2005-02-20 08:57:54.304822\n",
      "New data appended for date: 2005-02-20 09:57:54.304822\n",
      "New data appended for date: 2005-02-20 10:57:54.304822\n",
      "New data appended for date: 2005-02-20 11:57:54.304822\n",
      "New data appended for date: 2005-02-20 12:57:54.304822\n",
      "New data appended for date: 2005-02-20 13:57:54.304822\n",
      "New data appended for date: 2005-02-20 14:57:54.304822\n",
      "New data appended for date: 2005-02-20 15:57:54.304822\n",
      "New data appended for date: 2005-02-20 16:57:54.304822\n",
      "New data appended for date: 2005-02-20 17:57:54.304822\n",
      "New data appended for date: 2005-02-20 18:57:54.304822\n",
      "New data appended for date: 2005-02-20 19:57:54.304822\n",
      "New data appended for date: 2005-02-20 20:57:54.304822\n",
      "New data appended for date: 2005-02-20 21:57:54.304822\n",
      "New data appended for date: 2005-02-20 22:57:54.304822\n",
      "New data appended for date: 2005-02-20 23:57:54.304822\n",
      "New data appended for date: 2005-02-21 00:57:54.304822\n",
      "New data appended for date: 2005-02-21 01:57:54.304822\n",
      "New data appended for date: 2005-02-21 02:57:54.304822\n",
      "New data appended for date: 2005-02-21 03:57:54.304822\n",
      "New data appended for date: 2005-02-21 04:57:54.304822\n",
      "New data appended for date: 2005-02-21 05:57:54.304822\n",
      "New data appended for date: 2005-02-21 06:57:54.304822\n",
      "New data appended for date: 2005-02-21 07:57:54.304822\n",
      "New data appended for date: 2005-02-21 08:57:54.304822\n",
      "New data appended for date: 2005-02-21 09:57:54.304822\n",
      "New data appended for date: 2005-02-21 10:57:54.304822\n",
      "New data appended for date: 2005-02-21 11:57:54.304822\n",
      "New data appended for date: 2005-02-21 12:57:54.304822\n",
      "New data appended for date: 2005-02-21 13:57:54.304822\n",
      "New data appended for date: 2005-02-21 14:57:54.304822\n",
      "New data appended for date: 2005-02-21 15:57:54.304822\n",
      "New data appended for date: 2005-02-21 16:57:54.304822\n",
      "New data appended for date: 2005-02-21 17:57:54.304822\n",
      "New data appended for date: 2005-02-21 18:57:54.304822\n",
      "New data appended for date: 2005-02-21 19:57:54.304822\n",
      "New data appended for date: 2005-02-21 20:57:54.304822\n",
      "New data appended for date: 2005-02-21 21:57:54.304822\n",
      "New data appended for date: 2005-02-21 22:57:54.304822\n",
      "New data appended for date: 2005-02-21 23:57:54.304822\n",
      "New data appended for date: 2005-02-22 00:57:54.304822\n",
      "New data appended for date: 2005-02-22 01:57:54.304822\n",
      "New data appended for date: 2005-02-22 02:57:54.304822\n",
      "New data appended for date: 2005-02-22 03:57:54.304822\n",
      "New data appended for date: 2005-02-22 04:57:54.304822\n",
      "New data appended for date: 2005-02-22 05:57:54.304822\n",
      "New data appended for date: 2005-02-22 06:57:54.304822\n",
      "New data appended for date: 2005-02-22 07:57:54.304822\n",
      "New data appended for date: 2005-02-22 08:57:54.304822\n",
      "New data appended for date: 2005-02-22 09:57:54.304822\n",
      "New data appended for date: 2005-02-22 10:57:54.304822\n",
      "New data appended for date: 2005-02-22 11:57:54.304822\n",
      "New data appended for date: 2005-02-22 12:57:54.304822\n",
      "New data appended for date: 2005-02-22 13:57:54.304822\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 73\u001b[0m\n\u001b[1;32m     71\u001b[0m current_date \u001b[38;5;241m=\u001b[39m start_date\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m current_date \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m end_date:\n\u001b[0;32m---> 73\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_air_quality_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new_data:\n\u001b[1;32m     75\u001b[0m         append_data_to_csv(new_data, CSV_FILE_PATH)\n",
      "Cell \u001b[0;32mIn[13], line 16\u001b[0m, in \u001b[0;36mfetch_air_quality_data\u001b[0;34m(timestamp)\u001b[0m\n\u001b[1;32m     14\u001b[0m request_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mAPI_URL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&timestamp=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(timestamp\u001b[38;5;241m.\u001b[39mtimestamp())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Adjust according to the actual API format\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()  \u001b[38;5;66;03m# Raise an error for bad responses (4xx or 5xx)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    809\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 467\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:1099\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[0;32m-> 1099\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mproxy_is_verified:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connection.py:616\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    615\u001b[0m     sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    617\u001b[0m     server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[1;32m    618\u001b[0m     tls_in_tls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connection.py:198\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m:return: New socket connection.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 198\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[1;32m     75\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# Define the API endpoint and token\n",
    "API_URL = \"https://api.waqi.info/feed/here/?token=f72812a3dce2b2328992b2b06e42f4bc8e9f30da\"\n",
    "CSV_FILE_PATH = \"air_quality_feature_store.csv\"\n",
    "\n",
    "# Function to fetch data from the API\n",
    "def fetch_air_quality_data(timestamp):\n",
    "    \n",
    "    request_url = f\"{API_URL}&timestamp={int(timestamp.timestamp())}\"  # Adjust according to the actual API format\n",
    "    try:\n",
    "        response = requests.get(request_url)\n",
    "        response.raise_for_status()  # Raise an error for bad responses (4xx or 5xx)\n",
    "        \n",
    "        data = response.json()\n",
    "        if 'data' in data and data['data'] is not None:\n",
    "            iaqi = data['data'].get('iaqi', {})\n",
    "            # Extract features\n",
    "            features = {\n",
    "                \"temperature\": iaqi.get(\"t\", {}).get(\"v\", None),\n",
    "                \"humidity\": iaqi.get(\"h\", {}).get(\"v\", None),\n",
    "                \"pressure\": iaqi.get(\"p\", {}).get(\"v\", None),\n",
    "                \"wind_speed\": iaqi.get(\"w\", {}).get(\"v\", None),\n",
    "                \"wind_direction\": iaqi.get(\"wd\", {}).get(\"v\", None),\n",
    "                \"pm25\": iaqi.get(\"pm25\", {}).get(\"v\", None),\n",
    "                \"pm10\": iaqi.get(\"pm10\", {}).get(\"v\", None),\n",
    "                \"no2\": iaqi.get(\"no2\", {}).get(\"v\", None),\n",
    "                \"so2\": iaqi.get(\"so2\", {}).get(\"v\", None),\n",
    "                \"o3\": iaqi.get(\"o3\", {}).get(\"v\", None),\n",
    "                \"co\": iaqi.get(\"co\", {}).get(\"v\", None)\n",
    "            }\n",
    "            # Extract target (AQI)\n",
    "            target = data['data'].get(\"aqi\", None)\n",
    "\n",
    "            return {\n",
    "                \"location_id\": \"delhi_mandir_marg\",\n",
    "                \"event_timestamp\": timestamp,  # Use the passed timestamp\n",
    "                **features,  # Unpack features into the return dictionary\n",
    "                \"target\": target  # Include target in the return dictionary\n",
    "            }\n",
    "        else:\n",
    "            print(\"No data found in API response.\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"Error fetching data:\", e)\n",
    "        return None\n",
    "\n",
    "# Function to append data to CSV\n",
    "def append_data_to_csv(data_dict, file_path):\n",
    "    # Check if the file exists to write the header only if needed\n",
    "    file_exists = os.path.isfile(file_path)\n",
    "    df = pd.DataFrame([data_dict])\n",
    "    \n",
    "    try:\n",
    "        if not file_exists:\n",
    "            df.to_csv(file_path, index=False, mode='w')  # Create new file with header\n",
    "        else:\n",
    "            df.to_csv(file_path, index=False, mode='a', header=False)  # Append without header\n",
    "    except Exception as e:\n",
    "        print(\"Error writing to CSV:\", e)\n",
    "\n",
    "# Define the date range for historical data (e.g., past 7 days)\n",
    "start_date = datetime.utcnow() - timedelta(days=7200)  # Adjust the range as needed\n",
    "end_date = datetime.utcnow()\n",
    "\n",
    "# Generate timestamps for each hour in the date range\n",
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "    new_data = fetch_air_quality_data(current_date)\n",
    "    if new_data:\n",
    "        append_data_to_csv(new_data, CSV_FILE_PATH)\n",
    "        print(\"New data appended for date:\", new_data[\"event_timestamp\"])\n",
    "    \n",
    "    # Move to the next hour\n",
    "    current_date += timedelta(hours=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Air Quality data for New Delhi:\n",
      "  Station Name: Delhi Institute of Tool Engineering, Wazirpur, Delhi, Delhi, India, Location: [28.700505, 77.165603], AQI: 499\n",
      "  Station Name: Satyawati College, Delhi, Delhi, India, Location: [28.69572, 77.181295], AQI: 493\n",
      "  Station Name: ITI Shahdra, Jhilmil Industrial Area, Delhi, Delhi, India, Location: [28.672114, 77.313832], AQI: 429\n",
      "  Station Name: Sonia Vihar Water Treatment Plant DJB, Delhi, Delhi, India, Location: [28.710066, 77.24622], AQI: 414\n",
      "  Station Name: PGDAV College, Sriniwaspuri, Delhi, Delhi, India, Location: [28.566827, 77.251418], AQI: 393\n",
      "  Station Name: Pusa, Delhi, Delhi, India, Location: [28.636997, 77.172248], AQI: 384\n",
      "  Station Name: R.K. Puram, Delhi, Delhi, India, Location: [28.5648, 77.1744], AQI: 353\n",
      "  Station Name: Major Dhyan Chand National Stadium, Delhi, Delhi, India, Location: [28.612498, 77.237388], AQI: 335\n",
      "  Station Name: Mandir Marg, Delhi, Delhi, India, Location: [28.6341, 77.2005], AQI: 303\n",
      "  Station Name: New Delhi US Embassy, India (नई दिल्ली अमेरिकी दूतावास), Location: [28.63576, 77.22445], AQI: 288\n",
      "  Station Name: Mother Dairy Plant, Parparganj, Delhi, Delhi, India, Location: [28.620171, 77.287705], AQI: 283\n",
      "  Station Name: Jawaharlal Nehru Stadium, Delhi, Delhi, India, Location: [28.582846, 77.234366], AQI: 269\n",
      "  Station Name: Sector-1, Noida, India, Location: [28.5898, 77.3101], AQI: 178\n",
      "  Station Name: IHBAS, Delhi, Delhi, India, Location: [28.68189167, 77.30485833], AQI: -\n",
      "  Station Name: Lodhi Road, Delhi, Delhi, India, Location: [28.589701, 77.221917], AQI: -\n",
      "  Station Name: Burari Crossing, Delhi, Delhi, India, Location: [28.725646, 77.203384], AQI: -\n",
      "  Station Name: CRRI Mathura Road, Delhi, Delhi, India, Location: [28.551729, 77.275037], AQI: -\n",
      "  Station Name: Siri Fort, Delhi, Delhi, India, Location: [28.550138, 77.213379], AQI: -\n",
      "  Station Name: North Campus, Delhi, Delhi, India, Location: [28.687716, 77.210232], AQI: -\n",
      "  Station Name: Civil Lines, Delhi, Delhi, India, Location: [28.6787, 77.2262], AQI: -\n",
      "  Station Name: ITO, Delhi, Delhi, India, Location: [28.628577, 77.241036], AQI: -\n",
      "Air Quality data for Delhi:\n",
      "  Station Name: ITI Jahangirpuri, Delhi, Delhi, India, Location: [28.733016, 77.17197], AQI: 577\n",
      "  Station Name: Delhi Institute of Tool Engineering, Wazirpur, Delhi, Delhi, India, Location: [28.700505, 77.165603], AQI: 499\n",
      "  Station Name: Satyawati College, Delhi, Delhi, India, Location: [28.69572, 77.181295], AQI: 493\n",
      "  Station Name: ITI Shahdra, Jhilmil Industrial Area, Delhi, Delhi, India, Location: [28.672114, 77.313832], AQI: 429\n",
      "  Station Name: Sonia Vihar Water Treatment Plant DJB, Delhi, Delhi, India, Location: [28.710066, 77.24622], AQI: 414\n",
      "  Station Name: PGDAV College, Sriniwaspuri, Delhi, Delhi, India, Location: [28.566827, 77.251418], AQI: 393\n",
      "  Station Name: Pusa, Delhi, Delhi, India, Location: [28.636997, 77.172248], AQI: 384\n",
      "  Station Name: R.K. Puram, Delhi, Delhi, India, Location: [28.5648, 77.1744], AQI: 353\n",
      "  Station Name: Major Dhyan Chand National Stadium, Delhi, Delhi, India, Location: [28.612498, 77.237388], AQI: 335\n",
      "  Station Name: Anand Vihar, Delhi, Delhi, India, Location: [28.6508, 77.3152], AQI: 335\n",
      "  Station Name: Mandir Marg, Delhi, Delhi, India, Location: [28.6341, 77.2005], AQI: 303\n",
      "  Station Name: New Delhi US Embassy, India (नई दिल्ली अमेरिकी दूतावास), Location: [28.63576, 77.22445], AQI: 288\n",
      "  Station Name: Mother Dairy Plant, Parparganj, Delhi, Delhi, India, Location: [28.620171, 77.287705], AQI: 283\n",
      "  Station Name: Jawaharlal Nehru Stadium, Delhi, Delhi, India, Location: [28.582846, 77.234366], AQI: 269\n",
      "  Station Name: Sector-1, Noida, India, Location: [28.5898, 77.3101], AQI: 178\n",
      "  Station Name: IHBAS, Delhi, Delhi, India, Location: [28.68189167, 77.30485833], AQI: -\n",
      "  Station Name: Lodhi Road, Delhi, Delhi, India, Location: [28.589701, 77.221917], AQI: -\n",
      "  Station Name: Burari Crossing, Delhi, Delhi, India, Location: [28.725646, 77.203384], AQI: -\n",
      "  Station Name: North Campus, Delhi, Delhi, India, Location: [28.687716, 77.210232], AQI: -\n",
      "  Station Name: Civil Lines, Delhi, Delhi, India, Location: [28.6787, 77.2262], AQI: -\n",
      "  Station Name: ITO, Delhi, Delhi, India, Location: [28.628577, 77.241036], AQI: -\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Replace with your actual API token\n",
    "API_TOKEN = \"f72812a3dce2b2328992b2b06e42f4bc8e9f30da\"\n",
    "\n",
    "# List of known cities/neighborhoods in Delhi\n",
    "cities = [\"New Delhi\", \"Delhi\"]\n",
    "\n",
    "# Iterate over the list of cities and fetch air quality data\n",
    "for city in cities:\n",
    "    request_url = f\"https://api.waqi.info/search/?token={API_TOKEN}&keyword={city}\"\n",
    "    \n",
    "    response = requests.get(request_url)\n",
    "    response.raise_for_status()  # Raise an error for bad responses (4xx or 5xx)\n",
    "    \n",
    "    data = response.json()\n",
    "    \n",
    "    # Check if any data was returned\n",
    "    if data[\"data\"]:\n",
    "        print(f\"Air Quality data for {city}:\")\n",
    "        for entry in data[\"data\"]:\n",
    "            print(f\"  Station Name: {entry['station']['name']}, \"\n",
    "                  f\"Location: {entry['station']['geo']}, \"\n",
    "                  f\"AQI: {entry['aqi']}\")\n",
    "    else:\n",
    "        print(f\"No data found for {city}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for delhi/pooth_khurd at 2022-10-26 07:14:08.689059: {\"status\":\"error\",\"data\":\"Unknown station\"}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 117\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m current_date \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m end_date:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m city \u001b[38;5;129;01min\u001b[39;00m CITIES:\n\u001b[0;32m--> 117\u001b[0m         new_data \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_air_quality_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_data:\n\u001b[1;32m    119\u001b[0m             append_data_to_csv(new_data, CSV_FILE_PATH)\n",
      "Cell \u001b[0;32mIn[24], line 61\u001b[0m, in \u001b[0;36mfetch_air_quality_data\u001b[0;34m(city, timestamp)\u001b[0m\n\u001b[1;32m     59\u001b[0m data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 61\u001b[0m     iaqi \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miaqi\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# Extract features\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     features \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: iaqi\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhumidity\u001b[39m\u001b[38;5;124m\"\u001b[39m: iaqi\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mco\u001b[39m\u001b[38;5;124m\"\u001b[39m: iaqi\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mco\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     75\u001b[0m     }\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# Define the API endpoint and token\n",
    "API_URL = \"https://api.waqi.info/feed/\"\n",
    "API_TOKEN = \"f72812a3dce2b2328992b2b06e42f4bc8e9f30da\"\n",
    "CSV_FILE_PATH = \"air_quality_feature_store.csv\"\n",
    "CITIES = [\n",
    "    \"gurugram/sector-51\",\n",
    "    \"delhi/pooth_khurd\",\n",
    "    \"delhi/bramprakash_ayurvedic_hospital\",\n",
    "    \"delhi/delhi_institute_of_tool_engineering\",\n",
    "    \"gurugram/teri_gram\",\n",
    "    \"delhi/dr_karni_singh_shooting_range\",\n",
    "    \"delhi/major_dhyan_chand_national_stadium\",\n",
    "    \"delhi/national_institute_of_malaria_research\",\n",
    "    \"delhi/jawaharlal_nehru_stadium\",\n",
    "    \"delhi/narela\",\n",
    "    \"delhi/iti_shahdra\",\n",
    "    \"ghaziabad/loni\",\n",
    "    \"delhi/mundka\",\n",
    "    \"delhi/mother_dairy_plant\",\n",
    "    \"delhi/pgdav_college\",\n",
    "    \"delhi/iti_jahangirpuri\",\n",
    "    \"delhi/satyawati_college\",\n",
    "    \"faridabad/sector_30\",\n",
    "    \"gurugram/nise_gwal_pahari\",\n",
    "    \"delhi/rk_puram\",\n",
    "    \"delhi/pusa\",\n",
    "    \"delhi/sri_auribindo_marg\",\n",
    "    \"delhi/anand_vihar\",\n",
    "    \"delhi/alipur\",\n",
    "    \"bahadurgarh/arya_nagar\",\n",
    "    \"gurugram/vikas_sadan\",\n",
    "    \"delhi/mandir_marg\",\n",
    "    \"delhi/new_delhi_us_embassy\",\n",
    "    \"delhi/sonia_vihar_water_treatment_plant\",\n",
    "    \"delhi/punjabi_bagh\",\n",
    "    \"delhi/shaheed_sukhdev_college_of_business_studies\",\n",
    "    \"faridabad/sector16A\",\n",
    "    \"delhi/dite_okhla\",\n",
    "    \"noida/sector_125\",\n",
    "    \"noida/sector-1\"\n",
    "]\n",
    "\n",
    "\n",
    "# Function to fetch data from the API for a given city\n",
    "def fetch_air_quality_data(city, timestamp):\n",
    "    request_url = f\"{API_URL}{city}/?token={API_TOKEN}&timestamp={int(timestamp.timestamp())}\"\n",
    "    try:\n",
    "        response = requests.get(request_url)\n",
    "        response.raise_for_status()  # Raise an error for bad responses (4xx or 5xx)\n",
    "\n",
    "        # Log the raw response text for debugging\n",
    "        print(f\"Response for {city} at {timestamp}: {response.text}\")\n",
    "\n",
    "        data = response.json()\n",
    "        if isinstance(data, dict) and 'data' in data and data['data'] is not None:\n",
    "            iaqi = data['data'].get('iaqi', {})\n",
    "            # Extract features\n",
    "            features = {\n",
    "                \"temperature\": iaqi.get(\"t\", {}).get(\"v\", None),\n",
    "                \"humidity\": iaqi.get(\"h\", {}).get(\"v\", None),\n",
    "                \"pressure\": iaqi.get(\"p\", {}).get(\"v\", None),\n",
    "                \"wind_speed\": iaqi.get(\"w\", {}).get(\"v\", None),\n",
    "                \"wind_direction\": iaqi.get(\"wd\", {}).get(\"v\", None),\n",
    "                \"pm25\": iaqi.get(\"pm25\", {}).get(\"v\", None),\n",
    "                \"pm10\": iaqi.get(\"pm10\", {}).get(\"v\", None),\n",
    "                \"no2\": iaqi.get(\"no2\", {}).get(\"v\", None),\n",
    "                \"so2\": iaqi.get(\"so2\", {}).get(\"v\", None),\n",
    "                \"o3\": iaqi.get(\"o3\", {}).get(\"v\", None),\n",
    "                \"co\": iaqi.get(\"co\", {}).get(\"v\", None)\n",
    "            }\n",
    "            # Extract target (AQI) and rename it to 'aqi'\n",
    "            aqi = data['data'].get(\"aqi\", None)\n",
    "\n",
    "            return {\n",
    "                \"location_id\": city,  # Use the city name as the location ID\n",
    "                \"city\": city.split(\"/\")[1].replace(\"_\", \" \"),  # Extract and format the city name\n",
    "                \"event_timestamp\": timestamp,  # Use the passed timestamp\n",
    "                **features,  # Unpack features into the return dictionary\n",
    "                \"aqi\": aqi  # Include aqi in the return dictionary\n",
    "            }\n",
    "        else:\n",
    "            print(f\"Unexpected data format for {city} at {timestamp}: {data}\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data for {city}: {e}\")\n",
    "        return None\n",
    "    except ValueError as ve:\n",
    "        print(f\"Error decoding JSON for {city} at {timestamp}: {ve}\")\n",
    "        return None\n",
    "\n",
    "# Function to append data to CSV\n",
    "def append_data_to_csv(data_dict, file_path):\n",
    "    file_exists = os.path.isfile(file_path)\n",
    "    df = pd.DataFrame([data_dict])\n",
    "    \n",
    "    try:\n",
    "        if not file_exists:\n",
    "            df.to_csv(file_path, index=False, mode='w')  # Create new file with header\n",
    "        else:\n",
    "            df.to_csv(file_path, index=False, mode='a', header=False)  # Append without header\n",
    "    except Exception as e:\n",
    "        print(\"Error writing to CSV:\", e)\n",
    "\n",
    "# Define the date range for historical data (e.g., past 740 days)\n",
    "start_date = datetime.utcnow() - timedelta(days=740)\n",
    "end_date = datetime.utcnow()\n",
    "\n",
    "# Generate timestamps for each hour in the date range\n",
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "    for city in CITIES:\n",
    "        new_data = fetch_air_quality_data(city, current_date)\n",
    "        if new_data:\n",
    "            append_data_to_csv(new_data, CSV_FILE_PATH)\n",
    "            print(f\"New data appended for {new_data['city']} at {new_data['event_timestamp']}\")\n",
    "    \n",
    "    # Move to the next hour\n",
    "    current_date += timedelta(hours=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch data from the API for a given city\n",
    "def fetch_air_quality_data(city, timestamp):\n",
    "    request_url = f\"{API_URL}{city}/?token={API_TOKEN}&timestamp={int(timestamp.timestamp())}\"\n",
    "    try:\n",
    "        response = requests.get(request_url)\n",
    "        response.raise_for_status()  # Raise an error for bad responses (4xx or 5xx)\n",
    "\n",
    "        # Log the raw response text for debugging\n",
    "        print(f\"Response for {city} at {timestamp}: {response.text}\")\n",
    "\n",
    "        data = response.json()\n",
    "        \n",
    "        # Check if the status is 'error' and handle it\n",
    "        if data.get(\"status\") == \"error\":\n",
    "            print(f\"API Error for {city} at {timestamp}: {data['data']}\")\n",
    "            return None\n",
    "\n",
    "        if isinstance(data, dict) and 'data' in data and data['data'] is not None:\n",
    "            iaqi = data['data'].get('iaqi', {})\n",
    "            # Extract features\n",
    "            features = {\n",
    "                \"temperature\": iaqi.get(\"t\", {}).get(\"v\", None),\n",
    "                \"humidity\": iaqi.get(\"h\", {}).get(\"v\", None),\n",
    "                \"pressure\": iaqi.get(\"p\", {}).get(\"v\", None),\n",
    "                \"wind_speed\": iaqi.get(\"w\", {}).get(\"v\", None),\n",
    "                \"wind_direction\": iaqi.get(\"wd\", {}).get(\"v\", None),\n",
    "                \"pm25\": iaqi.get(\"pm25\", {}).get(\"v\", None),\n",
    "                \"pm10\": iaqi.get(\"pm10\", {}).get(\"v\", None),\n",
    "                \"no2\": iaqi.get(\"no2\", {}).get(\"v\", None),\n",
    "                \"so2\": iaqi.get(\"so2\", {}).get(\"v\", None),\n",
    "                \"o3\": iaqi.get(\"o3\", {}).get(\"v\", None),\n",
    "                \"co\": iaqi.get(\"co\", {}).get(\"v\", None)\n",
    "            }\n",
    "            # Extract target (AQI) and rename it to 'aqi'\n",
    "            aqi = data['data'].get(\"aqi\", None)\n",
    "\n",
    "            return {\n",
    "                \"location_id\": city,  # Use the city name as the location ID\n",
    "                \"city\": city.split(\"/\")[1].replace(\"_\", \" \"),  # Extract and format the city name\n",
    "                \"event_timestamp\": timestamp,  # Use the passed timestamp\n",
    "                **features,  # Unpack features into the return dictionary\n",
    "                \"aqi\": aqi  # Include aqi in the return dictionary\n",
    "            }\n",
    "        else:\n",
    "            print(f\"Unexpected data format for {city} at {timestamp}: {data}\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data for {city}: {e}\")\n",
    "        return None\n",
    "    except ValueError as ve:\n",
    "        print(f\"Error decoding JSON for {city} at {timestamp}: {ve}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
